{
  "llm_provider": "openai",
  "model": "gpt-4o",
  "temperature": 0.7,
  "max_tokens": 4000,
  "custom_prompt": null,
  "debug_mode": false
}