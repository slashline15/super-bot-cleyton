{
  "llm_provider": "openai",
  "model": "gpt-4o",
  "temperature": 1.0,
  "max_tokens": 1000,
  "custom_prompt": false,
  "debug_mode": false
}